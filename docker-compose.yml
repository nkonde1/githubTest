# This Docker Compose file defines and runs the multi-container
# embedded finance and analytics platform.

services:
  # --- PostgreSQL Database Service ---
  db:
    image: postgres:15-alpine
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-finance_db}
      POSTGRES_USER: ${POSTGRES_USER:-user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    volumes:
      - pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - finance_network

  # --- Redis Service ---
  redis:
    image: redis:7-alpine
    restart: always
    ports:
      - "6377:6379"
    command: redis-server --appendonly yes --port 6379
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - finance_network

  # --- Ollama AI Model Runner Service ---
  ollama:
    image: ollama/ollama:latest
    restart: always
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 60s
    networks:
      - finance_network

  # --- Custom AI Agent Service (NEW) ---
  ai_agent:
    build:
      context: ./ai_agent
      dockerfile: Dockerfile
    restart: always
    ports:
      - "8080:8080"
    environment:
      # This tells the AI Agent where to find the Ollama service within the Docker network
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - finance_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # --- Backend FastAPI Service (Updated) ---
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    ports:
      - "8000:8000"
    env_file:
      - ./backend/.env
    environment:
      # This tells the Backend where to find the AI Agent service within the Docker network
      - AI_AGENT_URL=http://ai_agent:8080
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      ai_agent:
        condition: service_healthy
    networks:
      - finance_network

  # --- Celery Worker Service (Updated) ---
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    env_file:
      - ./backend/.env
    environment:
      # The Celery worker also needs to know the AI agent URL
      - AI_AGENT_URL=http://ai_agent:8080
    command: celery -A app.main.celery_app worker --loglevel=info
    depends_on:
      - redis
      - db
      - backend
      - ai_agent
    networks:
      - finance_network
    volumes:
      - ./backend:/app

  # --- Frontend React.js Service ---
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    restart: always
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    env_file:
      - ./frontend/.env
    depends_on:
      - backend
    networks:
      - finance_network
    command: npm run dev

volumes:
  pg_data: {}
  redis_data: {}
  ollama_data: {}

networks:
  finance_network:
    driver: bridge
